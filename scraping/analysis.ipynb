{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc648388",
   "metadata": {},
   "source": [
    "# Закон Ципфа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9047a4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path().resolve() / \"src\"))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from typing import List\n",
    "from Stemmer import Stemmer\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from log import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32191c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RU_STEMMER = Stemmer(\"russian\")\n",
    "EN_STEMMER = Stemmer(\"english\")\n",
    "\n",
    "\n",
    "def load_texts_from_mongodb(\n",
    "    uri=\"mongodb://root:example@localhost:27017\", limit=5000\n",
    ") -> list[str]:\n",
    "    client = MongoClient(uri)\n",
    "\n",
    "    db = client[\"scraper\"]\n",
    "\n",
    "    collection = db[\"scraps\"]\n",
    "\n",
    "    texts = []\n",
    "    total_docs = collection.count_documents({})\n",
    "\n",
    "    log.info(f\"Найдено документов: {total_docs}\")\n",
    "\n",
    "    batch_size = 10000\n",
    "    processed = 0\n",
    "\n",
    "    for doc in collection.find({}, {\"value\": 1}).batch_size(batch_size):\n",
    "        if \"value\" in doc and doc[\"value\"]:\n",
    "            texts.append(doc[\"value\"])\n",
    "\n",
    "        processed += 1\n",
    "        if processed % 1000 == 0:\n",
    "            log.info(f\"Обработано {processed}/{total_docs} документов\")\n",
    "        if processed >= limit:\n",
    "            break\n",
    "\n",
    "    client.close()\n",
    "    log.info(f\"Загружено {len(texts)} текстов\")\n",
    "\n",
    "    return texts\n",
    "\n",
    "\n",
    "def is_cyrillic(char: str) -> bool:\n",
    "    if len(char.encode(\"utf-8\")) >= 2:\n",
    "        bytes_val = char.encode(\"utf-8\")\n",
    "        if len(bytes_val) >= 2:\n",
    "            return \"\\u0400\" <= char <= \"\\u04ff\"\n",
    "    return False\n",
    "\n",
    "\n",
    "def normalize_text_utf8(text: str) -> str:\n",
    "    if not text:\n",
    "        return \"\"\n",
    "\n",
    "    result = []\n",
    "    i = 0\n",
    "    text_len = len(text)\n",
    "\n",
    "    while i < text_len:\n",
    "        char = text[i]\n",
    "        if ord(char) < 128:\n",
    "            if char.isalnum():\n",
    "                result.append(char.lower())\n",
    "            else:\n",
    "                result.append(\" \")\n",
    "            i += 1\n",
    "        else:\n",
    "            if is_cyrillic(char):\n",
    "                lower_char = char.lower()\n",
    "                result.append(lower_char)\n",
    "            else:\n",
    "                result.append(\" \")\n",
    "            i += 1\n",
    "\n",
    "    return \"\".join(result)\n",
    "\n",
    "\n",
    "def tokenize_and_stem(text: str) -> List[str]:\n",
    "    if not text:\n",
    "        return []\n",
    "\n",
    "    normalized = normalize_text_utf8(text)\n",
    "\n",
    "    tokens = []\n",
    "    current_token = []\n",
    "\n",
    "    for char in normalized:\n",
    "        if char != \" \":\n",
    "            current_token.append(char)\n",
    "        else:\n",
    "            if current_token:\n",
    "                token = \"\".join(current_token)\n",
    "                if token:\n",
    "                    tokens.append(token)\n",
    "                current_token = []\n",
    "\n",
    "    if current_token:\n",
    "        token = \"\".join(current_token)\n",
    "        if token:\n",
    "            tokens.append(token)\n",
    "\n",
    "    stemmed_tokens = []\n",
    "    for token in tokens:\n",
    "        has_cyrillic = any(is_cyrillic(c) for c in token)\n",
    "\n",
    "        if has_cyrillic:\n",
    "            stemmed = RU_STEMMER.stemWord(token)\n",
    "        else:\n",
    "            stemmed = EN_STEMMER.stemWord(token)\n",
    "\n",
    "        if len(stemmed) > 2:\n",
    "            stemmed_tokens.append(stemmed)\n",
    "\n",
    "    return stemmed_tokens\n",
    "\n",
    "\n",
    "def build_zipf_law(tokens: List[str]):\n",
    "    word_counts = Counter(tokens)\n",
    "\n",
    "    sorted_counts = word_counts.most_common()\n",
    "\n",
    "    ranks = list(range(1, len(sorted_counts) + 1))\n",
    "    frequencies = [count for _, count in sorted_counts]\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    plt.loglog(ranks, frequencies, \"ro-\", linewidth=2, alpha=0.7, markersize=4)\n",
    "    plt.xlabel(\"Ранг слова (log)\", fontsize=12)\n",
    "    plt.ylabel(\"Частота (log)\", fontsize=12)\n",
    "    plt.title(\"Закон Ципфа (логарифмический масштаб)\", fontsize=14)\n",
    "    plt.grid(True, alpha=0.3, which=\"both\")\n",
    "\n",
    "    if len(ranks) > 1:\n",
    "        zipf_freq = [frequencies[0] / r for r in ranks]\n",
    "        plt.loglog(\n",
    "            ranks,\n",
    "            zipf_freq,\n",
    "            \"g--\",\n",
    "            linewidth=1,\n",
    "            alpha=0.5,\n",
    "            label=\"Теоретическая кривая Ципфа\",\n",
    "        )\n",
    "        plt.legend()\n",
    "\n",
    "    plt.suptitle(\n",
    "        f\"Закон Ципфа\\nВсего уникальных слов: {len(sorted_counts)} | Всего токенов: {len(tokens)}\",\n",
    "        fontsize=16,\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Всего токенов: {len(tokens)}\")\n",
    "    print(f\"Уникальных токенов: {len(sorted_counts)}\")\n",
    "    print(f\"Средняя длина токена: {sum(map(len, tokens)) / len(tokens)}\")\n",
    "\n",
    "    print(\"\\nТоп-10 самых частых слов:\")\n",
    "    for i, (word, count) in enumerate(sorted_counts[:10], 1):\n",
    "        percentage = (count / len(tokens)) * 100\n",
    "        print(f\"{i:2d}. {word:20s} - {count:6d} ({percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5a8132",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = load_texts_from_mongodb(limit=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dac7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenize_and_stem(\" \".join(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef3ba57",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_zipf_law(tokens)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
